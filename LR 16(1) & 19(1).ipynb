{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c165817-ae19-4f3f-b6a4-1754496244e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Scraping all news data...\n",
      "  Scraping page 1 (using empty POST data)...\n",
      "    -> Identified Board Meeting for HWAWELLTEX under LR 16(1)\n",
      "    -> Identified Board Meeting for RDFOOD under LR 16(1)\n",
      "    -> Identified Board Meeting for ECABLES under LR 19(1)\n",
      "    -> Identified Board Meeting for ARGONDENIM under LR 16(1)\n",
      "    -> Identified Board Meeting for SAFKOSPINN under LR 16(1)\n",
      "    -> Identified Board Meeting for ETL under LR 16(1)\n",
      "    -> Identified Board Meeting for SONALIANSH under LR 19(1)\n",
      "    -> Identified Board Meeting for COPPERTECH under LR 16(1)\n",
      "    -> Identified Board Meeting for PREMIERCEM under LR 16(1)\n",
      "    -> Identified Board Meeting for BSCPLC under LR 16(1)\n",
      "    -> Identified Board Meeting for SONALIPAPR under LR 16(1)\n",
      "    -> Identified Board Meeting for BPPL under LR 16(1)\n",
      "    -> Identified Board Meeting for BDCOM under LR 16(1)\n",
      "    -> Identified Board Meeting for BARKAPOWER under LR 16(1)\n",
      "    -> Identified Board Meeting for SUMITPOWER under LR 16(1)\n",
      "    -> Identified Board Meeting for SAIHAMTEX under LR 16(1)\n",
      "    -> Identified Board Meeting for TAMIJTEX under LR 16(1)\n",
      "    -> Identified Board Meeting for SAIHAMCOT under LR 16(1)\n",
      "    -> Identified Board Meeting for DSSL under LR 16(1)\n",
      "    -> Identified Board Meeting for RANFOUNDRY under LR 16(1)\n",
      "    -> Identified Board Meeting for SAPORTL under LR 16(1)\n",
      "    -> Identified Board Meeting for KAY&QUE under LR 16(1)\n",
      "    -> Identified Board Meeting for ACFL under LR 16(1)\n",
      "    -> Identified Board Meeting for AMANFEED under LR 16(1)\n",
      "    -> Identified Board Meeting for MIRAKHTER under LR 16(1)\n",
      "    -> Identified Board Meeting for MEGHNACEM under LR 16(1)\n",
      "    -> Identified Board Meeting for BPML under LR 16(1)\n",
      "    -> Identified Board Meeting for AMCL(PRAN) under LR 16(1)\n",
      "  -> Parsed 95 items from page 1.\n",
      "\n",
      "Step 2: Processing Board Meeting data (separating by LR, sorting, formatting)...\n",
      "  -> Processed 26 LR 16(1) board meeting entries.\n",
      "  -> Processed 2 LR 19(1) board meeting entries.\n",
      "\n",
      "Step 3: Saving data to Excel...\n",
      "  -> Saved 95 news items to 'All News' sheet.\n",
      "  -> Saved 26 sorted & formatted LR 16(1) items to 'LR 16(1)' sheet.\n",
      "  -> Saved 2 sorted & formatted LR 19(1) items to 'LR 19(1)' sheet.\n",
      "\n",
      "Successfully saved all data to LR_News_2025-11-11.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re # For regular expressions to extract dates and details\n",
    "from datetime import datetime # For getting today's date\n",
    "\n",
    "def scrape_dse_news_multiple_pages_corrected(base_url, session_cookie=None, max_pages=1, delay=1):\n",
    "    \"\"\"\n",
    "    Scrapes news data, identifies Board Meeting Schedule items based on LR references,\n",
    "    extracts relevant details, and uses a predefined sector list.\n",
    "    Saves all data to an Excel file with separate sheets for All News, LR 16(1), and LR 19(1),\n",
    "    named with today's date. Applies date formatting and sentence case.\n",
    "    \"\"\"\n",
    "    all_news_data = []\n",
    "    board_meeting_data = []\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"text/html, */*; q=0.01\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Host\": \"www.dse.com.bd\",\n",
    "        \"Origin\": \"https://www.dse.com.bd\",\n",
    "        \"Referer\": \"https://www.dse.com.bd/display_news.php\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0\",\n",
    "        \"X-KL-kes-Ajax-Request\": \"Ajax_Request\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua\": '\"Microsoft Edge\";v=\"141\", \"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"141\"',\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "    }\n",
    "\n",
    "    cookies = {}\n",
    "    if session_cookie:\n",
    "         cookies['PHPSESSID'] = session_cookie\n",
    "\n",
    "    # --- Predefined Sector Mapping ---\n",
    "    sector_mapping = {\n",
    "        \"1JANATAMF\": \"M. Fund\", \"1STBSRS\": \"\", \"1STICB\": \"\", \"1STPRIMFMF\": \"M. Fund\", \"2NDICB\": \"\",\n",
    "        \"3RDICB\": \"\", \"4THICB\": \"\", \"5THICB\": \"\", \"6THICB\": \"\", \"7THICB\": \"\", \"8THICB\": \"\",\n",
    "        \"AAMRANET\": \"IT\", \"AAMRATECH\": \"IT\", \"ABB1STMF\": \"M. Fund\", \"ABBANK\": \"Bank\", \"ACFL\": \"Textile\",\n",
    "        \"ACI\": \"Pharma\", \"ACIFORMULA\": \"Pharma\", \"ACIZCBOND\": \"\", \"ACMELAB\": \"Pharma\", \"ACMEPL\": \"Pharma\",\n",
    "        \"ACTIVEFINE\": \"Pharma\", \"ADNTEL\": \"IT\", \"ADVENT\": \"Pharma\", \"AFCAGRO\": \"Pharma\", \"AFTABAUTO\": \"Engineering\",\n",
    "        \"AGNISYSL\": \"IT\", \"AGRANINS\": \"General Insurance\", \"AIBL1STIMF\": \"M. Fund\", \"AIL\": \"Textile\",\n",
    "        \"AIMS1STMF\": \"\", \"ALARABANK\": \"Bank\", \"AL-HAJTEX\": \"Textile\", \"ALIF\": \"Textile\", \"ALLTEX\": \"Textile\",\n",
    "        \"AMANFEED\": \"Miscellaneous\", \"AMBEEPHA\": \"Pharma\", \"AMCL(PRAN)\": \"Food & Allied\", \"ANLIMAYARN\": \"Textile\",\n",
    "        \"ANWARGALV\": \"Engineering\", \"AOL\": \"Fuel & Power\", \"APEXFOODS\": \"Food & Allied\", \"APEXFOOT\": \"Tannery\",\n",
    "        \"APEXSPINN\": \"Textile\", \"APEXTANRY\": \"Tannery\", \"APOLOISPAT\": \"Engineering\", \"APSCLBOND\": \"BOND\",\n",
    "        \"ARAMIT\": \"Miscellaneous\", \"ARAMITCEM\": \"Cement\", \"ARGONDENIM\": \"Textile\", \"ASIAINS\": \"General Insurance\",\n",
    "        \"ASIAPACINS\": \"General Insurance\", \"ASIATICLAB\": \"Pharma\", \"ATCSLGF\": \"M. Fund\", \"ATLASBANG\": \"Engineering\",\n",
    "        \"AZIZPIPES\": \"Engineering\", \"BANGAS\": \"Food & Allied\", \"BANKASIA\": \"Bank\", \"BARKAPOWER\": \"Fuel & Power\",\n",
    "        \"BATASHOE\": \"Tannery\", \"BATBC\": \"Food & Allied\", \"BAYLEASING\": \"NBFI\", \"BBS\": \"Engineering\",\n",
    "        \"BBSCABLES\": \"Engineering\", \"BDAUTOCA\": \"Engineering\", \"BDCOM\": \"IT\", \"BDFINANCE\": \"NBFI\",\n",
    "        \"BDLAMPS\": \"Engineering\", \"BDSERVICE\": \"Travel & Leisure\", \"BDTHAI\": \"Engineering\", \"BDTHAIFOOD\": \"Food & Allied\",\n",
    "        \"BDWELDING\": \"Fuel & Power\", \"BEACHHATCH\": \"Food & Allied\", \"BEACONPHAR\": \"Pharma\", \"BENGALWTL\": \"Engineering\",\n",
    "        \"BERGERPBL\": \"Miscellaneous\", \"BESTHLDNG\": \"Travel & Leisure\", \"BEXIMCO\": \"Miscellaneous\", \"BGIC\": \"General Insurance\",\n",
    "        \"BIFC\": \"NBFI\", \"BNICL\": \"General Insurance\", \"BPML\": \"Paper & Printing\", \"BPPL\": \"Fuel & Power\",\n",
    "        \"BRACBANK\": \"Bank\", \"BRACSCBOND\": \"\", \"BSC\": \"Miscellaneous\", \"BSCPLC\": \"Telecom\", \"BSRMLTD\": \"Engineering\",\n",
    "        \"BSRMSTEEL\": \"Engineering\", \"BXPHARMA\": \"Pharma\", \"BXSYNTH\": \"\", \"CAPITECGBF\": \"M. Fund\",\n",
    "        \"CAPMBDBLMF\": \"M. Fund\", \"CAPMIBBLMF\": \"M. Fund\", \"CENTRALINS\": \"General Insurance\", \"CENTRALPHL\": \"Pharma\",\n",
    "        \"CITYBANK\": \"Bank\", \"CITYGENINS\": \"General Insurance\", \"CLICL\": \"Life Insurance\", \"CNATEX\": \"Textile\",\n",
    "        \"CONFIDCEM\": \"Cement\", \"CONTININS\": \"General Insurance\", \"COPPERTECH\": \"Engineering\", \"CROWNCEMNT\": \"Cement\",\n",
    "        \"CRYSTALINS\": \"General Insurance\", \"CVOPRL\": \"Fuel & Power\", \"DACCADYE\": \"Textile\", \"DAFODILCOM\": \"IT\",\n",
    "        \"DBH\": \"NBFI\", \"DBH1STMF\": \"M. Fund\", \"DELTALIFE\": \"Life Insurance\", \"DELTASPINN\": \"Textile\",\n",
    "        \"DESCO\": \"Fuel & Power\", \"DESHBANDHU\": \"Engineering\", \"DGIC\": \"General Insurance\", \"DHAKABANK\": \"Bank\",\n",
    "        \"DHAKAINS\": \"General Insurance\", \"DOMINAGE\": \"Engineering\", \"DOREENPWR\": \"Fuel & Power\", \"DSHGARME\": \"Textile\",\n",
    "        \"DSSL\": \"Textile\", \"DULAMIACOT\": \"Textile\", \"DUTCHBANGL\": \"Bank\", \"EASTERNINS\": \"General Insurance\",\n",
    "        \"EASTLAND\": \"General Insurance\", \"EASTRNLUB\": \"Fuel & Power\", \"EBL\": \"Bank\", \"EBL1STMF\": \"M. Fund\",\n",
    "        \"EBLNRBMF\": \"M. Fund\", \"ECABLES\": \"Engineering\", \"EGEN\": \"IT\", \"EHL\": \"Service & RE\", \"EIL\": \"General Insurance\",\n",
    "        \"EMERALDOIL\": \"Food & Allied\", \"ENVOYTEX\": \"Textile\", \"EPGL\": \"Fuel & Power\", \"ESQUIRENIT\": \"Textile\",\n",
    "        \"ETL\": \"Textile\", \"EXIM1STMF\": \"M. Fund\", \"EXIMBANK\": \"Bank\", \"FAMILYTEX\": \"Textile\", \"FARCHEM\": \"Pharma\",\n",
    "        \"FAREASTFIN\": \"NBFI\", \"FAREASTLIF\": \"Life Insurance\", \"FASFIN\": \"NBFI\", \"FBFIF\": \"M. Fund\",\n",
    "        \"FEDERALINS\": \"General Insurance\", \"FEKDIL\": \"Textile\", \"FINEFOODS\": \"Food & Allied\", \"FIRSTFIN\": \"NBFI\",\n",
    "        \"FIRSTSBANK\": \"Bank\", \"FORTUNE\": \"Tannery\", \"FUWANGCER\": \"Ceramics\", \"FUWANGFOOD\": \"Food & Allied\",\n",
    "        \"GBBPOWER\": \"Fuel & Power\", \"GEMINISEA\": \"Food & Allied\", \"GENEXIL\": \"IT\", \"GENNEXT\": \"Textile\",\n",
    "        \"GHAIL\": \"Food & Allied\", \"GHCL\": \"Pharma\", \"GIB\": \"Bank\", \"GLDNJMF\": \"M. Fund\", \"GLOBALINS\": \"General Insurance\",\n",
    "        \"GOLDENSON\": \"Engineering\", \"GP\": \"Telecom\", \"GPHISPAT\": \"Engineering\", \"GQBALLPEN\": \"Miscellaneous\",\n",
    "        \"GRAMEEN1\": \"\", \"GRAMEENS2\": \"M. Fund\", \"GREENDELMF\": \"M. Fund\", \"GREENDELT\": \"General Insurance\",\n",
    "        \"GSPFINANCE\": \"NBFI\", \"HAKKANIPUL\": \"Paper & Printing\", \"HAMI\": \"Pharma\", \"HEIDELBCEM\": \"Cement\",\n",
    "        \"HFL\": \"Textile\", \"HRTEX\": \"Textile\", \"HWAWELLTEX\": \"Textile\", \"IBBLPBOND\": \"Bond\", \"IBNSINA\": \"Pharma\",\n",
    "        \"IBP\": \"Pharma\", \"ICB\": \"NBFI\", \"ICB1STNRB\": \"\", \"ICB2NDNRB\": \"\", \"ICB3RDNRB\": \"M. Fund\",\n",
    "        \"ICBAGRANI1\": \"M. Fund\", \"ICBAMCL1ST\": \"\", \"ICBAMCL2ND\": \"M. Fund\", \"ICBEPMF1S1\": \"M. Fund\", \"ICBIBANK\": \"Bank\",\n",
    "        \"ICBISLAMIC\": \"\", \"ICBSONALI1\": \"M. Fund\", \"ICICL\": \"General Insurance\", \"IDLC\": \"NBFI\", \"IFADAUTOS\": \"Engineering\",\n",
    "        \"IFIC\": \"Bank\", \"IFIC1STMF\": \"M. Fund\", \"IFILISLMF1\": \"M. Fund\", \"ILFSL\": \"NBFI\", \"INDEXAGRO\": \"Miscellaneous\",\n",
    "        \"INTECH\": \"IT\", \"INTRACO\": \"Fuel & Power\", \"IPDC\": \"NBFI\", \"ISLAMIBANK\": \"Bank\", \"ISLAMICFIN\": \"NBFI\",\n",
    "        \"ISLAMIINS\": \"General Insurance\", \"ISNLTD\": \"IT\", \"ITC\": \"IT\", \"JAMUNABANK\": \"Bank\", \"JAMUNAOIL\": \"Fuel & Power\",\n",
    "        \"JANATAINS\": \"General Insurance\", \"JHRML\": \"Miscellaneous\", \"JMISMDL\": \"Pharma\", \"JUTESPINN\": \"Jute\",\n",
    "        \"KARNAPHULI\": \"General Insurance\", \"KAY&QUE\": \"Engineering\", \"KBPPWBIL\": \"Miscellaneous\", \"KDSALTD\": \"Engineering\",\n",
    "        \"KEYACOSMET\": \"Pharma\", \"KOHINOOR\": \"Pharma\", \"KPCL\": \"Fuel & Power\", \"KPPL\": \"Paper & Printing\",\n",
    "        \"KTL\": \"Textile\", \"LANKABAFIN\": \"NBFI\", \"LEGACYFOOT\": \"Tannery\", \"LHB\": \"Cement\", \"LIBRAINFU\": \"Pharma\",\n",
    "        \"LINDEBD\": \"Fuel & Power\", \"LOVELLO\": \"Food & Allied\", \"LRBDL\": \"Fuel & Power\", \"LRGLOBMF1\": \"M. Fund\",\n",
    "        \"MAGURAPLEX\": \"Paper & Printing\", \"MAKSONSPIN\": \"Textile\", \"MALEKSPIN\": \"Textile\", \"MARICO\": \"Pharma\",\n",
    "        \"MATINSPINN\": \"Textile\", \"MBL1STMF\": \"M. Fund\", \"MEGCONMILK\": \"Food & Allied\", \"MEGHNACEM\": \"Cement\",\n",
    "        \"MEGHNAINS\": \"General Insurance\", \"MEGHNALIFE\": \"Life Insurance\", \"MEGHNAPET\": \"Food & Allied\", \"MERCANBANK\": \"Bank\",\n",
    "        \"MERCINS\": \"General Insurance\", \"METROSPIN\": \"Textile\", \"MHSML\": \"Textile\", \"MIDASFIN\": \"NBFI\",\n",
    "        \"MIDLANDBNK\": \"Bank\", \"MIRACLEIND\": \"Miscellaneous\", \"MIRAKHTER\": \"Engineering\", \"MITHUNKNIT\": \"Textile\",\n",
    "        \"MJLBD\": \"Fuel & Power\", \"MLDYEING\": \"Textile\", \"MODERNDYE\": \"Textile\", \"MONNOAGML\": \"Engineering\",\n",
    "        \"MONNOCERA\": \"Ceramics\", \"MONNOFABR\": \"Textile\", \"MONOSPOOL\": \"Paper & Printing\", \"MPETROLEUM\": \"Fuel & Power\",\n",
    "        \"MTB\": \"Bank\", \"NAHEEACP\": \"Engineering\", \"NATLIFEINS\": \"Life Insurance\", \"NAVANACNG\": \"Engineering\",\n",
    "        \"NAVANAPHAR\": \"Pharma\", \"NBL\": \"Bank\", \"NCCBANK\": \"Bank\", \"NCCBLMF1\": \"M. Fund\", \"NEWLINE\": \"Textile\",\n",
    "        \"NFML\": \"Miscellaneous\", \"NHFIL\": \"NBFI\", \"NITOLINS\": \"General Insurance\", \"NLI1STMF\": \"M. Fund\",\n",
    "        \"NORTHERN\": \"Jute\", \"NORTHRNINS\": \"General Insurance\", \"NPOLYMER\": \"Engineering\", \"NRBBANK\": \"Bank\",\n",
    "        \"NRBCBANK\": \"Bank\", \"NTC\": \"Food & Allied\", \"NTLTUBES\": \"Engineering\", \"NURANI\": \"Textile\", \"OAL\": \"Engineering\",\n",
    "        \"OIMEX\": \"Engineering\", \"OLYMPIC\": \"Food & Allied\", \"ONEBANKPLC\": \"Bank\", \"ORIONINFU\": \"Pharma\",\n",
    "        \"ORIONPHARM\": \"Pharma\", \"PADMALIFE\": \"Life Insurance\", \"PADMAOIL\": \"Fuel & Power\", \"PARAMOUNT\": \"General Insurance\",\n",
    "        \"PDL\": \"Textile\", \"PENINSULA\": \"Travel & Leisure\", \"PEOPLESINS\": \"General Insurance\", \"PF1STMF\": \"M. Fund\",\n",
    "        \"PHARMAID\": \"Pharma\", \"PHENIXINS\": \"General Insurance\", \"PHOENIXFIN\": \"NBFI\", \"PHPMF1\": \"M. Fund\",\n",
    "        \"PIONEERINS\": \"General Insurance\", \"PLFSL\": \"NBFI\", \"POPULAR1MF\": \"M. Fund\", \"POPULARLIF\": \"Life Insurance\",\n",
    "        \"POWERGRID\": \"Fuel & Power\", \"PRAGATIINS\": \"General Insurance\", \"PRAGATILIF\": \"Life Insurance\",\n",
    "        \"PREMIERBAN\": \"Bank\", \"PREMIERCEM\": \"Cement\", \"PREMIERLEA\": \"NBFI\", \"PRIME1ICBA\": \"M. Fund\", \"PRIMEBANK\": \"Bank\",\n",
    "        \"PRIMEFIN\": \"NBFI\", \"PRIMEINSUR\": \"General Insurance\", \"PRIMELIFE\": \"Life Insurance\", \"PRIMETEX\": \"Textile\",\n",
    "        \"PROGRESLIF\": \"Life Insurance\", \"PROVATIINS\": \"General Insurance\", \"PTL\": \"Textile\", \"PUBALIBANK\": \"Bank\",\n",
    "        \"PURABIGEN\": \"General Insurance\", \"QUASEMIND\": \"Engineering\", \"QUEENSOUTH\": \"Textile\", \"RAHIMAFOOD\": \"Food & Allied\",\n",
    "        \"RAHIMTEXT\": \"Textile\", \"RAKCERAMIC\": \"Ceramics\", \"RANFOUNDRY\": \"Engineering\", \"RDFOOD\": \"Food & Allied\",\n",
    "        \"RECKITTBEN\": \"Pharma\", \"REGENTTEX\": \"Textile\", \"RELIANCE1\": \"M. Fund\", \"RELIANCINS\": \"General Insurance\",\n",
    "        \"RENATA\": \"Pharma\", \"RENWICKJA\": \"Engineering\", \"REPUBLIC\": \"General Insurance\", \"RINGSHINE\": \"Textile\",\n",
    "        \"ROBI\": \"Telecom\", \"RSRMSTEEL\": \"Engineering\", \"RUNNERAUTO\": \"Engineering\", \"RUPALIBANK\": \"Bank\",\n",
    "        \"RUPALIINS\": \"General Insurance\", \"RUPALILIFE\": \"Life Insurance\", \"SAFKOSPINN\": \"Textile\", \"SAIFPOWER\": \"Services & Real Estate\",\n",
    "        \"SAIHAMCOT\": \"Textile\", \"SAIHAMTEX\": \"Textile\", \"SALAMCRST\": \"Engineering\", \"SALVOCHEM\": \"Pharma\",\n",
    "        \"SAMATALETH\": \"Tannery\", \"SAMORITA\": \"Service & RE\", \"SANDHANINS\": \"Life Insurance\", \"SAPORTL\": \"Service & RE\",\n",
    "        \"SAVAREFR\": \"Miscellaneous\", \"SBACBANK\": \"Bank\", \"SEAPEARL\": \"Travel & Leisure\", \"SEBL1STMF\": \"M. Fund\",\n",
    "        \"SEMLFBSLGF\": \"M. Fund\", \"SEMLIBBLSF\": \"M. Fund\", \"SEMLLECMF\": \"M. Fund\", \"SHAHJABANK\": \"Bank\",\n",
    "        \"SHARPIND\": \"Textile\", \"SHASHADNIM\": \"Textile\", \"SHEPHERD\": \"Textile\", \"SHURWID\": \"Engineering\",\n",
    "        \"SHYAMPSUG\": \"Food & Allied\", \"SIBL\": \"Bank\", \"SILCOPHL\": \"Pharma\", \"SILVAPHL\": \"Pharma\", \"SIMTEX\": \"Textile\",\n",
    "        \"SINGERBD\": \"Engineering\", \"SINOBANGLA\": \"Miscellaneous\", \"SIPLC\": \"General Insurance\", \"SKTRIMS\": \"Miscellaneous\",\n",
    "        \"SONALIANSH\": \"Jute\", \"SONALILIFE\": \"Life Insurance\", \"SONALIPAPR\": \"Paper & Printing\", \"SONARBAINS\": \"General Insurance\",\n",
    "        \"SONARGAON\": \"Textile\", \"SOUTHEASTB\": \"Bank\", \"SPCERAMICS\": \"Ceramics\", \"SPCL\": \"Fuel & Power\",\n",
    "        \"SQUARETEXT\": \"Textile\", \"SQURPHARMA\": \"Pharma\", \"SSSTEEL\": \"Engineering\", \"STANCERAM\": \"Ceramics\",\n",
    "        \"STANDARINS\": \"General Insurance\", \"STANDBANKL\": \"Bank\", \"STYLECRAFT\": \"Textile\", \"SUMITPOWER\": \"Fuel & Power\",\n",
    "        \"SUNLIFEINS\": \"Life Insurance\", \"TAKAFULINS\": \"General Insurance\", \"TALLUSPIN\": \"Textile\", \"TAMIJTEX\": \"Textile\",\n",
    "        \"TECHNODRUG\": \"Pharma\", \"TILIL\": \"Life Insurance\", \"TITASGAS\": \"Fuel & Power\", \"TOSRIFA\": \"Textile\",\n",
    "        \"TRUSTB1MF\": \"M. Fund\", \"TRUSTBANK\": \"Bank\", \"TUNGHAI\": \"Textile\", \"UCB\": \"Bank\", \"UNILEVERCL\": \"Food & Allied\",\n",
    "        \"UNIONBANK\": \"Bank\", \"UNIONCAP\": \"NBFI\", \"UNIONINS\": \"General Insurance\", \"UNIQUEHRL\": \"Travel & Leisure\",\n",
    "        \"UNITEDAIR\": \"\", \"UNITEDFIN\": \"NBFI\", \"UNITEDINS\": \"General Insurance\", \"UPGDCL\": \"Fuel & Power\",\n",
    "        \"USMANIAGL\": \"Miscellaneous\", \"UTTARABANK\": \"Bank\", \"UTTARAFIN\": \"NBFI\", \"VAMLBDMF1\": \"M. Fund\",\n",
    "        \"VAMLRBBF\": \"M. Fund\", \"VFSTDL\": \"Textile\", \"WALTONHIL\": \"Engineering\", \"WATACHEM\": \"Pharma\",\n",
    "        \"WMSHIPYARD\": \"Engineering\", \"YPL\": \"Engineering\", \"ZAHEENSPIN\": \"Textile\", \"ZAHINTEX\": \"Textile\",\n",
    "        \"ZEALBANGLA\": \"Food & Allied\"\n",
    "    }\n",
    "\n",
    "\n",
    "    # --- Step 1: Scrape all News Data ---\n",
    "    print(\"Step 1: Scraping all news data...\")\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        print(f\"  Scraping page {page_num} (using empty POST data)...\")\n",
    "\n",
    "        post_data = {} # Using empty data based on successful debug result\n",
    "\n",
    "        try:\n",
    "            response = requests.post(base_url, headers=headers, cookies=cookies, data=post_data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            rows = soup.find_all('tr')\n",
    "\n",
    "            if not rows:\n",
    "                 print(f\"    No <tr> tags found on page {page_num}. Stopping.\")\n",
    "                 break\n",
    "\n",
    "            current_item = {}\n",
    "            item_count = 0\n",
    "            for row in rows:\n",
    "                th = row.find('th')\n",
    "                td = row.find('td')\n",
    "\n",
    "                if th and td:\n",
    "                    header_text = th.get_text(strip=True)\n",
    "                    cell_text = td.get_text(strip=True)\n",
    "\n",
    "                    if \"Trading Code\" in header_text:\n",
    "                        current_item[\"Trading Code\"] = cell_text\n",
    "                    elif \"News Title\" in header_text:\n",
    "                        current_item[\"News Title\"] = cell_text\n",
    "                    elif \"News\" in header_text:\n",
    "                        current_item[\"News\"] = cell_text\n",
    "                    elif \"Post Date\" in header_text:\n",
    "                        current_item[\"Post Date\"] = cell_text\n",
    "                        if len(current_item) == 4:\n",
    "                            all_news_data.append(current_item.copy())\n",
    "                            # --- Check for Board Meeting Schedule ---\n",
    "                            news_title = current_item[\"News Title\"]\n",
    "                            # Look for LR 16(1) or LR 19(1) in the title\n",
    "                            lr_match = re.search(r'LR\\s*(?:16\\(1\\)|19\\(1\\))', news_title, re.IGNORECASE)\n",
    "                            if lr_match:\n",
    "                                lr_ref = lr_match.group(0).strip() # Get the matched string like \"LR 16(1)\"\n",
    "                                trading_code = current_item[\"Trading Code\"]\n",
    "                                full_news_text = current_item[\"News\"]\n",
    "\n",
    "                                # Extract meeting date using regex\n",
    "                                # Pattern looks for common date formats like \"Month DD, YYYY\" or \"DD Month YYYY\" or \"DD/MM/YYYY\" or \"YYYY-MM-DD\"\n",
    "                                date_pattern = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s+\\d{4}|' \\\n",
    "                                               r'\\d{1,2}\\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}|' \\\n",
    "                                               r'\\d{1,2}/\\d{1,2}/\\d{4}|' \\\n",
    "                                               r'\\d{4}-\\d{2}-\\d{2}'\n",
    "                                date_match = re.search(date_pattern, full_news_text)\n",
    "                                meeting_date_str = date_match.group(0) if date_match else \"Date Not Found\"\n",
    "\n",
    "                                # Extract details (text between \"to consider, among others,\" and the first period after it)\n",
    "                                details_pattern = r'to consider,\\s*among others,\\s*(.*?)(?:\\.|\\n|$)'\n",
    "                                details_match = re.search(details_pattern, full_news_text, re.IGNORECASE)\n",
    "                                details_text = details_match.group(1).strip() if details_match else \"Details Not Found\"\n",
    "\n",
    "                                # Get sector from the predefined mapping\n",
    "                                sector = sector_mapping.get(trading_code, \"Sector Not Found\")\n",
    "\n",
    "                                board_meeting_data.append({\n",
    "                                    \"SL\": len(board_meeting_data) + 1, # Serial number is the current length + 1\n",
    "                                    \"Company\": trading_code,\n",
    "                                    \"LR Reference\": lr_ref,\n",
    "                                    \"Meeting Schedule\": meeting_date_str, # Store as string initially for processing\n",
    "                                    \"Sector\": sector,\n",
    "                                    \"Details\": details_text\n",
    "                                })\n",
    "                                print(f\"    -> Identified Board Meeting for {trading_code} under {lr_ref}\")\n",
    "\n",
    "                            current_item = {}\n",
    "                            item_count += 1\n",
    "\n",
    "            print(f\"  -> Parsed {item_count} items from page {page_num}.\")\n",
    "\n",
    "            if item_count == 0:\n",
    "                 print(f\"  Warning: No complete news items found on page {page_num}.\")\n",
    "                 break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  An error occurred while fetching news page {page_num}: {e}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred on news page {page_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        if delay > 0:\n",
    "            time.sleep(delay)\n",
    "\n",
    "    # --- Step 2: Process Board Meeting Data (Separate, Date Conversion, Sorting, Formatting) ---\n",
    "    print(\"\\nStep 2: Processing Board Meeting data (separating by LR, sorting, formatting)...\")\n",
    "    lr16_data = []\n",
    "    lr19_data = []\n",
    "\n",
    "    if board_meeting_data:\n",
    "        for item in board_meeting_data:\n",
    "            if \"16(1)\" in item[\"LR Reference\"]:\n",
    "                lr16_data.append(item)\n",
    "            elif \"19(1)\" in item[\"LR Reference\"]:\n",
    "                lr19_data.append(item)\n",
    "\n",
    "        # Process LR 16(1) data\n",
    "        if lr16_data:\n",
    "            lr16_df = pd.DataFrame(lr16_data, columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"])\n",
    "            # Convert 'Meeting Schedule' column to datetime objects for sorting\n",
    "            lr16_df['Meeting Schedule Datetime'] = pd.to_datetime(lr16_df['Meeting Schedule'], format='%B %d, %Y', errors='coerce')\n",
    "            mask = lr16_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr16_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr16_df.loc[mask, 'Meeting Schedule'], format='%d %B %Y', errors='coerce')\n",
    "            mask = lr16_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr16_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr16_df.loc[mask, 'Meeting Schedule'], format='%d/%m/%Y', errors='coerce')\n",
    "            mask = lr16_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr16_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr16_df.loc[mask, 'Meeting Schedule'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            lr16_df.sort_values(by='Meeting Schedule Datetime', ascending=True, inplace=True)\n",
    "            lr16_df.reset_index(drop=True, inplace=True)\n",
    "            lr16_df['Details'] = lr16_df['Details'].apply(lambda x: x.capitalize() if pd.notna(x) else x)\n",
    "            lr16_df['Meeting Schedule'] = lr16_df['Meeting Schedule Datetime'].apply(lambda x: x.strftime('%d-%b-%y') if pd.notna(x) else x)\n",
    "            lr16_df.drop(columns=['Meeting Schedule Datetime'], inplace=True)\n",
    "            lr16_df['SL'] = range(1, len(lr16_df) + 1)\n",
    "            print(f\"  -> Processed {len(lr16_df)} LR 16(1) board meeting entries.\")\n",
    "        else:\n",
    "            lr16_df = pd.DataFrame(columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"]) # Create empty DataFrame with correct columns\n",
    "            print(\"  -> No LR 16(1) data found.\")\n",
    "\n",
    "        # Process LR 19(1) data\n",
    "        if lr19_data:\n",
    "            lr19_df = pd.DataFrame(lr19_data, columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"])\n",
    "            # Convert 'Meeting Schedule' column to datetime objects for sorting\n",
    "            lr19_df['Meeting Schedule Datetime'] = pd.to_datetime(lr19_df['Meeting Schedule'], format='%B %d, %Y', errors='coerce')\n",
    "            mask = lr19_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr19_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr19_df.loc[mask, 'Meeting Schedule'], format='%d %B %Y', errors='coerce')\n",
    "            mask = lr19_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr19_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr19_df.loc[mask, 'Meeting Schedule'], format='%d/%m/%Y', errors='coerce')\n",
    "            mask = lr19_df['Meeting Schedule Datetime'].isna()\n",
    "            if mask.any():\n",
    "                lr19_df.loc[mask, 'Meeting Schedule Datetime'] = pd.to_datetime(lr19_df.loc[mask, 'Meeting Schedule'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            lr19_df.sort_values(by='Meeting Schedule Datetime', ascending=True, inplace=True)\n",
    "            lr19_df.reset_index(drop=True, inplace=True)\n",
    "            lr19_df['Details'] = lr19_df['Details'].apply(lambda x: x.capitalize() if pd.notna(x) else x)\n",
    "            lr19_df['Meeting Schedule'] = lr19_df['Meeting Schedule Datetime'].apply(lambda x: x.strftime('%d-%b-%y') if pd.notna(x) else x)\n",
    "            lr19_df.drop(columns=['Meeting Schedule Datetime'], inplace=True)\n",
    "            lr19_df['SL'] = range(1, len(lr19_df) + 1)\n",
    "            print(f\"  -> Processed {len(lr19_df)} LR 19(1) board meeting entries.\")\n",
    "        else:\n",
    "            lr19_df = pd.DataFrame(columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"]) # Create empty DataFrame with correct columns\n",
    "            print(\"  -> No LR 19(1) data found.\")\n",
    "    else:\n",
    "        print(\"  -> No board meeting data found.\")\n",
    "        lr16_df = pd.DataFrame(columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"])\n",
    "        lr19_df = pd.DataFrame(columns=[\"SL\", \"Company\", \"LR Reference\", \"Meeting Schedule\", \"Sector\", \"Details\"])\n",
    "\n",
    "\n",
    "    # --- Step 3: Save to Excel with Today's Date in Filename ---\n",
    "    print(\"\\nStep 3: Saving data to Excel...\")\n",
    "    # Get today's date in YYYY-MM-DD format\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "    output_filename = f\"LR_News_{today_str}.xlsx\" # Construct the filename\n",
    "\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "            # Write main news data to 'All News' sheet\n",
    "            if all_news_data:\n",
    "                news_df = pd.DataFrame(all_news_data, columns=[\"Trading Code\", \"News Title\", \"News\", \"Post Date\"])\n",
    "                news_df.to_excel(writer, sheet_name='News', index=False)\n",
    "                print(f\"  -> Saved {len(all_news_data)} news items to 'All News' sheet.\")\n",
    "            else:\n",
    "                print(\"  -> No news data to save to 'News' sheet.\")\n",
    "\n",
    "            # Write processed LR 16(1) data to 'LR 16(1)' sheet\n",
    "            if not lr16_df.empty:\n",
    "                lr16_df.to_excel(writer, sheet_name='LR 16(1)', index=False)\n",
    "                print(f\"  -> Saved {len(lr16_df)} sorted & formatted LR 16(1) items to 'LR 16(1)' sheet.\")\n",
    "            else:\n",
    "                print(\"  -> No processed LR 16(1) data to save to 'LR 16(1)' sheet.\")\n",
    "\n",
    "            # Write processed LR 19(1) data to 'LR 19(1)' sheet\n",
    "            if not lr19_df.empty:\n",
    "                lr19_df.to_excel(writer, sheet_name='LR 19(1)', index=False)\n",
    "                print(f\"  -> Saved {len(lr19_df)} sorted & formatted LR 19(1) items to 'LR 19(1)' sheet.\")\n",
    "            else:\n",
    "                print(\"  -> No processed LR 19(1) data to save to 'LR 19(1)' sheet.\")\n",
    "\n",
    "        print(f\"\\nSuccessfully saved all data to {output_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the Excel file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_url = \"https://www.dsebd.org/old_news.php?startDate=2025-11-10&endDate=2025-11-10&criteria=4&archive=news\" # Removed extra spaces\n",
    "\n",
    "    session_id = None # e.g., \"aggc96j657rag8iva3du5lc4b3\"\n",
    "\n",
    "    # For the news endpoint, it seems to return the same batch with empty POST data.\n",
    "    # So max_pages=1 should get the latest batch.\n",
    "    max_pages_to_scrape = 1\n",
    "\n",
    "    request_delay = 1\n",
    "\n",
    "    scrape_dse_news_multiple_pages_corrected(\n",
    "        base_url=news_url,\n",
    "        session_cookie=session_id,\n",
    "        max_pages=max_pages_to_scrape,\n",
    "        delay=request_delay\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
